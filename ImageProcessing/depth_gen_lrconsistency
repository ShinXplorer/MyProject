#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Depth + Colored Point Cloud from a side-by-side stereo image (NO RESIZING) with robust cleanup.

Adds:
- Histogram match (right -> left) to reduce radiometric mismatch
- Stricter SGBM defaults
- Optional WLS refinement
- Left-right (LR) consistency masking
- Texture mask to suppress low-detail hallucinations
- Stronger speckle cleanup + small median
- Optional joint bilateral smoothing of disparity

Exports:
    - rectified images (PNG)
    - disparity (u8 PNG + color PNG + float32 NPY)
    - depth from Q (mm) as NPY + 16-bit PNG
    - depth from fx*B/d (meters) as NPY
    - Q, P1, P2 as NPY
    - colored point cloud PLY (meters) reprojected with Q (left colors)

Notes on units:
- reprojectImageTo3D with Q carries the units of T from calibration
- PLY is exported in meters (mm -> m if CALIB_T_UNIT == "mm")
"""

import os
from typing import Tuple, Dict, List, Optional
import numpy as np
import cv2
import open3d as o3d


# ========== EDIT THESE ==========
IMAGE_PATH = r"data/input_images/WIN_20250910_11_11_00_Pro.jpg"  # SBS image
CALIB_NPZ  = r"opencv_stereo_params2.npz"                        # your npz
OUTPUT_DIR = r"data/output/depth_only"
USE_WLS    = True                                                # needs opencv-contrib (cv2.ximgproc)

# Set to "mm" if your T is in millimeters; "m" if meters.
CALIB_T_UNIT = "mm"

# PLY export Z gate (same units as Q/T; converted to meters internally if "mm")
PLY_Z_MIN = 20.0
PLY_Z_MAX = 20000.0
# ===============================


# ---------- Helpers ----------

def load_npz_calibration(npz_path: str) -> Dict[str, np.ndarray | tuple]:
    """Load stereo calibration parameters from NPZ."""
    if not os.path.exists(npz_path):
        raise FileNotFoundError(npz_path)
    p = np.load(npz_path, allow_pickle=False)

    K1 = np.array(p["camera_matrix_1"])
    D1 = np.array(p["dist_coeffs_1"]).reshape(-1, 1)
    K2 = np.array(p["camera_matrix_2"])
    D2 = np.array(p["dist_coeffs_2"]).reshape(-1, 1)
    R  = np.array(p["R"])
    T  = np.array(p["T"]).reshape(3, 1)

    # image_size can be [H, W] or [W, H]; normalize to (W, H)
    image_size = tuple(np.array(p["image_size"]).tolist())
    if image_size[0] < image_size[1]:
        W, H = image_size[1], image_size[0]
    else:
        W, H = image_size

    return dict(K1=K1, D1=D1, K2=K2, D2=D2, R=R, T=T, size=(W, H))


def split_sbs(path: str) -> Tuple[np.ndarray, np.ndarray]:
    """Split an SBS image into left/right halves (no resize)."""
    img = cv2.imread(path, cv2.IMREAD_COLOR)
    if img is None:
        raise FileNotFoundError(f"Cannot read: {path}")
    h, w = img.shape[:2]
    if w % 2 != 0:
        raise ValueError(f"Width must be even for SBS. Got {w}")
    half = w // 2
    return img[:, :half].copy(), img[:, half:].copy()


def rectify_no_resize(left_bgr: np.ndarray, right_bgr: np.ndarray, calib: Dict) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    Rectify with NO resizing. Validates (W,H) of halves match calibration size.
    """
    Wc, Hc = calib["size"]
    Hl, Wl = left_bgr.shape[:2]
    Hr, Wr = right_bgr.shape[:2]

    if (Wl, Hl) != (Wc, Hc) or (Wr, Hr) != (Wc, Hc):
        raise ValueError(
            f"Input halves size mismatch with calibration.\n"
            f"  Left:  {(Wl, Hl)}\n"
            f"  Right: {(Wr, Hr)}\n"
            f"  Calib: {(Wc, Hc)}\n"
            f"Ensure your SBS halves equal the calibration size."
        )

    R1, R2, P1, P2, Q, _, _ = cv2.stereoRectify(
        calib["K1"], calib["D1"], calib["K2"], calib["D2"],
        (Wc, Hc), calib["R"], calib["T"],
        flags=cv2.CALIB_ZERO_DISPARITY, alpha=0
    )

    map1L, map2L = cv2.initUndistortRectifyMap(calib["K1"], calib["D1"], R1, P1, (Wc, Hc), cv2.CV_16SC2)
    map1R, map2R = cv2.initUndistortRectifyMap(calib["K2"], calib["D2"], R2, P2, (Wc, Hc), cv2.CV_16SC2)

    rectL = cv2.remap(left_bgr,  map1L, map2L, cv2.INTER_LINEAR)
    rectR = cv2.remap(right_bgr, map1R, map2R, cv2.INTER_LINEAR)
    return rectL, rectR, P1, P2, Q


def match_histogram_to(src_gray: np.ndarray, ref_gray: np.ndarray) -> np.ndarray:
    """Histogram match src_gray intensities to ref_gray."""
    src = src_gray.ravel()
    ref = ref_gray.ravel()
    s_values, bin_idx, s_counts = np.unique(src, return_inverse=True, return_counts=True)
    r_values, r_counts = np.unique(ref, return_counts=True)
    s_quant = np.cumsum(s_counts).astype(np.float64); s_quant /= s_quant[-1]
    r_quant = np.cumsum(r_counts).astype(np.float64); r_quant /= r_quant[-1]
    interp = np.interp(s_quant, r_quant, r_values)
    return interp[bin_idx].reshape(src_gray.shape).astype(np.uint8)


def lr_consistency_mask(dispL: np.ndarray, dispR: np.ndarray, thresh: float = 1.0) -> np.ndarray:
    """
    Returns a boolean mask where LR is consistent within 'thresh' pixels.
    dispL: left disparity (float32, px)
    dispR: right disparity (float32, px)
    """
    H, W = dispL.shape
    xs = np.arange(W, dtype=np.float32)[None, :].repeat(H, axis=0)
    xr = xs - dispL                    # project L -> R
    xr_i = np.round(xr).astype(np.int32)

    valid = (dispL > 0)
    valid &= (xr_i >= 0) & (xr_i < W)

    dispR_samp = np.zeros_like(dispL, dtype=np.float32)
    rows = np.arange(H)[:, None]
    dispR_samp[valid] = dispR[rows, xr_i][valid]

    agree = np.abs(dispL - dispR_samp) <= thresh
    mask = valid & agree & (dispR_samp > 0)
    return mask


def texture_mask(gray: np.ndarray, ksize: int = 3, grad_thresh: float = 8.0) -> np.ndarray:
    """Boolean mask of pixels with enough local gradient magnitude."""
    gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=ksize)
    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=ksize)
    mag = cv2.magnitude(gx, gy)
    p = np.percentile(mag, 60)  # ignore flattest ~60 percent by default
    t = max(grad_thresh, 0.5 * p)
    return (mag >= t)


# ---------- Disparity / Depth ----------

def compute_disparity(rectL_bgr: np.ndarray,
                      rectR_bgr: np.ndarray,
                      num_disp: int = 240,
                      block_size: int = 5,
                      use_wls: bool = True,
                      strict: bool = True) -> Tuple[np.ndarray, Optional[np.ndarray], np.ndarray]:
    """
    Returns:
        dispL (float32, px)  -- final (possibly relaxed)
        dispR (float32, px) or None
        grayL (uint8)
    """
    def build_sgbm(bs: int, uniq: int, p2_mult: int, speckle_rng: int) -> cv2.StereoSGBM:
        nd = int(np.ceil(num_disp / 16.0)) * 16
        bs = bs if bs % 2 == 1 else bs + 1
        return cv2.StereoSGBM_create(
            minDisparity=0,
            numDisparities=nd,
            blockSize=bs,
            P1=8 * bs * bs,
            P2=p2_mult * bs * bs,        # 32..96 * bs^2
            disp12MaxDiff=1,
            uniquenessRatio=uniq,         # 10..20
            speckleWindowSize=200,
            speckleRange=speckle_rng,     # 1..4
            preFilterCap=31,
            mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY
        )

    # ---- Preprocess
    grayL = cv2.cvtColor(rectL_bgr, cv2.COLOR_BGR2GRAY)
    grayR = cv2.cvtColor(rectR_bgr, cv2.COLOR_BGR2GRAY)

    grayL = cv2.bilateralFilter(grayL, 9, 50, 50)
    grayR = cv2.bilateralFilter(grayR, 9, 50, 50)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    grayL = clahe.apply(grayL)
    grayR = clahe.apply(grayR)

    # Histogram match right->left (helps radiometric mismatch)
    def match_histogram_to(src_gray: np.ndarray, ref_gray: np.ndarray) -> np.ndarray:
        src = src_gray.ravel()
        ref = ref_gray.ravel()
        s_values, bin_idx, s_counts = np.unique(src, return_inverse=True, return_counts=True)
        r_values, r_counts = np.unique(ref, return_counts=True)
        s_quant = np.cumsum(s_counts).astype(np.float64); s_quant /= s_quant[-1]
        r_quant = np.cumsum(r_counts).astype(np.float64); r_quant /= r_quant[-1]
        interp = np.interp(s_quant, r_quant, r_values)
        return interp[bin_idx].reshape(src_gray.shape).astype(np.uint8)

    grayR = match_histogram_to(grayR, grayL)

    # ---- Pass A: stricter (good scenes)
    params_list = []
    if strict:
        params_list.append(dict(bs=block_size, uniq=15, p2=64, speck=2))
    # Pass B: relaxed a bit
    params_list.append(dict(bs=max(5, block_size), uniq=12, p2=48, speck=3))
    # Pass C: more relaxed (last resort)
    params_list.append(dict(bs=max(5, block_size), uniq=10, p2=32, speck=4))

    chosen = None
    dispL_raw = None
    dispR_raw = None

    for i, prm in enumerate(params_list, 1):
        sgbm = build_sgbm(prm["bs"], prm["uniq"], prm["p2"], prm["speck"])
        dispL16 = sgbm.compute(grayL, grayR)
        if use_wls and hasattr(cv2, "ximgproc"):
            right_matcher = cv2.ximgproc.createRightMatcher(sgbm)
            dispR16 = right_matcher.compute(grayR, grayL)

            wls = cv2.ximgproc.createDisparityWLSFilter(matcher_left=sgbm)
            # WLS a bit stronger on stricter pass, gentler on relaxed passes
            wls.setLambda(20000.0 if i == 1 else (16000.0 if i == 2 else 12000.0))
            wls.setSigmaColor(0.8 if i == 1 else (1.0 if i == 2 else 1.2))

            dispL = wls.filter(dispL16, rectL_bgr, disparity_map_right=dispR16).astype(np.float32) / 16.0
            dispR = dispR16.astype(np.float32) / 16.0
        else:
            dispL = dispL16.astype(np.float32) / 16.0
            sgbmR = build_sgbm(prm["bs"], prm["uniq"], prm["p2"], prm["speck"])
            dispR = sgbmR.compute(grayR, grayL).astype(np.float32) / 16.0

        # keep first raw pair (for debug/fallback)
        if dispL_raw is None:
            dispL_raw = dispL.copy()
            dispR_raw = dispR.copy()

        raw_valid = dispL > 0
        print(f"[SGBM pass {i}] raw valid = {_valid_pct(raw_valid):.2f}%  (bs={prm['bs']}, uniq={prm['uniq']}, p2={prm['p2']}, speck={prm['speck']})")

        # Speckle prune (early)
        d16 = (dispL * 16.0).astype(np.int16)
        cv2.filterSpeckles(d16, 0, 0, 2 * 16)
        dispL = d16.astype(np.float32) / 16.0
        dispL[dispL < 0] = 0.0
        post_speck = dispL > 0
        print(f"[SGBM pass {i}] after speckle valid = {_valid_pct(post_speck):.2f}%")

        # LR consistency
        def lr_consistency_mask(dL: np.ndarray, dR: np.ndarray, thresh: float) -> np.ndarray:
            H, W = dL.shape
            xs = np.arange(W, dtype=np.float32)[None, :].repeat(H, axis=0)
            xr = xs - dL
            xr_i = np.round(xr).astype(np.int32)
            valid = (dL > 0) & (xr_i >= 0) & (xr_i < W)
            rows = np.arange(H)[:, None]
            dR_s = np.zeros_like(dL, np.float32)
            dR_s[valid] = dR[rows, xr_i][valid]
            agree = np.abs(dL - dR_s) <= thresh
            return valid & agree & (dR_s > 0)

        # try strict LR threshold first, then relax if it nukes too much
        for lr_t in (1.0, 1.5, 2.0):
            lr_mask = lr_consistency_mask(dispL, dispR, thresh=lr_t)
            pct_lr = _valid_pct(lr_mask)
            print(f"[SGBM pass {i}] LR mask(th={lr_t}) keeps = {pct_lr:.2f}%")
            if pct_lr >= 1.0 or lr_t == 2.0:  # require at least 1% or stop at 2.0
                break

        # texture mask (skip if too destructive)
        def texture_mask(gray: np.ndarray, ksize: int = 3, grad_thresh: float = 8.0) -> np.ndarray:
            gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=ksize)
            gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=ksize)
            mag = cv2.magnitude(gx, gy)
            p = np.percentile(mag, 60)
            t = max(grad_thresh, 0.5 * p)
            return (mag >= t)

        tex = texture_mask(grayL, ksize=3, grad_thresh=8.0)
        pct_tex = _valid_pct(tex)
        print(f"[SGBM pass {i}] texture keeps ~{pct_tex:.2f}% of pixels (scene-wise)")

        valid_mask = lr_mask & tex
        pct_valid_mask = _valid_pct(valid_mask)
        print(f"[SGBM pass {i}] combined mask keeps = {pct_valid_mask:.2f}%")

        # If combined is too low, drop texture mask first, keep LR only
        if pct_valid_mask < 1.0 and _valid_pct(lr_mask) >= 1.0:
            valid_mask = lr_mask
            pct_valid_mask = _valid_pct(valid_mask)
            print(f"[SGBM pass {i}] dropping texture mask -> keeps {pct_valid_mask:.2f}%")

        # If still too low, accept post-speckle only (no LR/texture)
        if pct_valid_mask < 1.0 and _valid_pct(post_speck) >= 1.0:
            valid_mask = post_speck
            pct_valid_mask = _valid_pct(valid_mask)
            print(f"[SGBM pass {i}] dropping LR mask -> keeps {pct_valid_mask:.2f}%")

        # If still too low, accept raw (last resort for this pass)
        if pct_valid_mask < 1.0 and _valid_pct(raw_valid) >= 1.0:
            valid_mask = raw_valid
            pct_valid_mask = _valid_pct(valid_mask)
            print(f"[SGBM pass {i}] using raw disparity -> keeps {pct_valid_mask:.2f}%")

        # Finalize for this pass
        disp_final = dispL.copy()
        disp_final[~valid_mask] = 0.0

        # Median cleanup
        disp_final = cv2.medianBlur(disp_final, 3)

        final_valid = disp_final > 0
        pct_final = _valid_pct(final_valid)
        print(f"[SGBM pass {i}] FINAL valid = {pct_final:.2f}%")

        # Choose the first pass that yields something usable
        if pct_final >= 1.0:
            chosen = (disp_final, dispR, grayL)
            break

    if chosen is not None:
        return chosen

    # Nothing cleared 1% — return the least-bad raw (so pipeline doesn't crash)
    if dispL_raw is None:
        raise RuntimeError("Disparity failed unexpectedly (no raw).")
    print("[WARN] All refinement passes too strict; returning raw disparity to keep pipeline alive.")
    dispL_raw[dispL_raw < 0] = 0.0
    return dispL_raw, dispR_raw, grayL



def disparity_to_depth_Q(disp: np.ndarray, Q: np.ndarray) -> np.ndarray:
    """Depth via Q; Z in same units as T in calibration (likely mm)."""
    pts3d = cv2.reprojectImageTo3D(disp.astype(np.float32), Q)  # (H,W,3)
    Z = pts3d[..., 2].astype(np.float32)
    Z[~np.isfinite(Z)] = 0.0
    Z[disp <= 0] = 0.0
    return Z


def disparity_to_depth_fxB(disp: np.ndarray, P1: np.ndarray, P2: np.ndarray) -> np.ndarray:
    """Depth via Z = f*B/d; returns meters if baseline_m is meters."""
    fx = float(P1[0, 0])
    baseline_m = -float(P2[0, 3]) / fx
    Z = np.zeros_like(disp, dtype=np.float32)
    m = disp > 0
    if baseline_m != 0:
        Z[m] = (fx * baseline_m) / disp[m]
    return Z


def disp_to_vis(disp: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """8-bit and colorized disparity visualization."""
    vis = np.zeros_like(disp, dtype=np.uint8)
    m = disp > 0
    if np.any(m):
        v = disp[m]
        lo, hi = np.percentile(v, 2), np.percentile(v, 98)
        hi = max(hi, lo + 1e-6)
        vis[m] = np.clip(255 * (disp[m] - lo) / (hi - lo), 0, 255).astype(np.uint8)
    vis[~m] = 20
    return vis, cv2.applyColorMap(vis, cv2.COLORMAP_JET)

def _valid_pct(m: np.ndarray) -> float:
    return 100.0 * float(np.count_nonzero(m)) / float(m.size)

def _score_valid(d: np.ndarray) -> float:
    return float(np.count_nonzero(d > 0)) / float(d.size)


# ---------- Point Cloud Export ----------

def save_point_cloud_from_disparity(rect_left_bgr: np.ndarray,
                                    disparity: np.ndarray,
                                    Q: np.ndarray,
                                    out_ply_path: str,
                                    calib_t_unit: str = "mm",
                                    z_min: float = 50.0,
                                    z_max: float = 5000.0) -> None:
    """
    Build and save colored point cloud from disparity (PLY, meters), with auto-relax fallback
    if the initial Z-gated mask is empty.

    z_min and z_max are in the same units as Q's Z (same as T in calibration).
    """
    pts3d = cv2.reprojectImageTo3D(disparity.astype(np.float32), Q)
    Z = pts3d[..., 2]
    finite3d = np.isfinite(pts3d).all(axis=2)
    disp_ok = disparity > 0

    if not np.any(disp_ok):
        raise RuntimeError(
            "No positive disparities. Check rectification size, texture, and SGBM settings."
        )

    mask1 = disp_ok & finite3d & (Z > float(z_min)) & (Z < float(z_max))
    n1 = int(mask1.sum())

    if n1 == 0:
        Z_valid = Z[disp_ok & finite3d]
        if Z_valid.size == 0:
            raise RuntimeError("No finite 3D points after reprojectImageTo3D. Check calibration and Q.")
        p1 = float(np.percentile(Z_valid, 1))
        p99 = float(np.percentile(Z_valid, 99))
        if not np.isfinite(p1) or not np.isfinite(p99) or p99 <= p1:
            p1, p99 = float(np.min(Z_valid)), float(np.max(Z_valid))
        span = max(1e-6, (p99 - p1))
        z_auto_min = p1 - 0.02 * span
        z_auto_max = p99 + 0.02 * span
        mask = disp_ok & finite3d & (Z > z_auto_min) & (Z < z_auto_max)
        if not np.any(mask):
            mask = disp_ok & finite3d
    else:
        mask = mask1

    pts = pts3d[mask].astype(np.float32)
    cols_bgr = rect_left_bgr[mask].astype(np.float32) / 255.0
    cols_rgb = cols_bgr[:, ::-1]

    if calib_t_unit.lower() == "mm":
        pts *= 0.001  # mm -> m

    os.makedirs(os.path.dirname(out_ply_path) or ".", exist_ok=True)
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(pts.astype(np.float64))
    pcd.colors = o3d.utility.Vector3dVector(cols_rgb.astype(np.float64))
    ok = o3d.io.write_point_cloud(out_ply_path, pcd, write_ascii=True, print_progress=True)
    if not ok:
        raise IOError(f"Failed to save PLY: {out_ply_path}")
    print(f"[OK] Point cloud saved -> {out_ply_path}  (points: {len(pts)})")


# ---------- Main ----------

def main() -> None:
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    base = os.path.splitext(os.path.basename(IMAGE_PATH))[0]

    # 1) Load and split SBS
    left_bgr, right_bgr = split_sbs(IMAGE_PATH)

    # 2) Load calibration, rectify with NO resize
    calib = load_npz_calibration(CALIB_NPZ)
    rectL, rectR, P1, P2, Q = rectify_no_resize(left_bgr, right_bgr, calib)

    # 3) Try L->R as usual
    disp_A, dispR_A, _ = compute_disparity(rectL, rectR, num_disp=240, block_size=5, use_wls=USE_WLS, strict=True)
    score_A = _score_valid(disp_A)

    # 3b) Try R->L (swap) and rectify back by flipping disparity sign is unnecessary here;
    # we only compare valid coverage to pick the better direction to KEEP.
    disp_B, dispR_B, _ = compute_disparity(rectR, rectL, num_disp=240, block_size=5, use_wls=USE_WLS, strict=True)
    score_B = _score_valid(disp_B)

    if score_B > score_A * 1.2:  # noticeably better
        print(f"[AUTO-ORDER] Using RIGHT->LEFT direction (valid {100*score_B:.2f}% vs {100*score_A:.2f}%)")
        # Recompute against original orientation so following code (depth, Q) stays consistent:
        disp, dispR, grayL = compute_disparity(rectL, rectR, num_disp=240, block_size=5, use_wls=USE_WLS, strict=False)
    else:
        print(f"[AUTO-ORDER] Using LEFT->RIGHT (valid {100*score_A:.2f}% vs {100*score_B:.2f}%)")
        disp, dispR, grayL = disp_A, dispR_A, None

    # 3) Disparity with cleanup
    
    disp, dispR, grayL = compute_disparity(rectL, rectR, num_disp=240, block_size=5, use_wls=USE_WLS)

    # 4) Depth maps (two ways)
    depth_mm_from_Q  = disparity_to_depth_Q(disp, Q)         # likely mm
    depth_m_from_fxB = disparity_to_depth_fxB(disp, P1, P2)  # meters

    # 5) Disparity visualization
    disp_u8, disp_col = disp_to_vis(disp)

    # 6) Save images and arrays
    cv2.imwrite(os.path.join(OUTPUT_DIR, f"{base}_rect_left.png"), rectL)
    cv2.imwrite(os.path.join(OUTPUT_DIR, f"{base}_rect_right.png"), rectR)
    cv2.imwrite(os.path.join(OUTPUT_DIR, f"{base}_disparity_gray.png"), disp_u8)
    cv2.imwrite(os.path.join(OUTPUT_DIR, f"{base}_disparity_color.png"), disp_col)

    np.save(os.path.join(OUTPUT_DIR, f"{base}_disp_float32.npy"), disp.astype(np.float32))
    np.save(os.path.join(OUTPUT_DIR, f"{base}_depth_Q_mm.npy"),   depth_mm_from_Q.astype(np.float32))
    np.save(os.path.join(OUTPUT_DIR, f"{base}_depth_fxB_m.npy"),  depth_m_from_fxB.astype(np.float32))

    # 7) Also export a 16-bit depth PNG (millimeters from Q)
    depth_mm16 = np.clip(depth_mm_from_Q, 0, 65535).astype(np.uint16)
    cv2.imwrite(os.path.join(OUTPUT_DIR, f"{base}_depth_Q_mm16.png"), depth_mm16)

    # 8) Save intrinsics/extrinsics slices for reproducibility
    np.save(os.path.join(OUTPUT_DIR, f"{base}_Q.npy"),  Q.astype(np.float64))
    np.save(os.path.join(OUTPUT_DIR, f"{base}_P1.npy"), P1.astype(np.float64))
    np.save(os.path.join(OUTPUT_DIR, f"{base}_P2.npy"), P2.astype(np.float64))

    # 9) Colored point cloud (PLY) — output in meters
    ply_out = os.path.join(OUTPUT_DIR, f"{base}_pointcloud_from_Q.ply")
    save_point_cloud_from_disparity(rectL, disp, Q, ply_out,
                                    calib_t_unit=CALIB_T_UNIT,
                                    z_min=PLY_Z_MIN, z_max=PLY_Z_MAX)

    # 10) Quick stats
    valid = disp > 0
    print(f"Valid disparity: {valid.sum()}/{disp.size} = {100*valid.mean():.2f}%")
    if valid.any():
        v = disp[valid]
        print(f"d min/max p1/p99: {v.min():.2f}/{v.max():.2f}  {np.percentile(v,1):.2f}/{np.percentile(v,99):.2f}")
        print(f"Depth median (Q, mm): {np.median(depth_mm_from_Q[valid]):.1f}")

    print("[DONE] Depth maps and point cloud exported.")


if __name__ == "__main__":
    main()
